# LLM Serving Systems
Orca - https://usenix.org/system/files/osdi22-yu.pdf

vLLM - https://arxiv.org/abs/2309.06180

Sarathi-serve - https://arxiv.org/abs/2403.02310

# LLM Inference

Sarathi - https://arxiv.org/abs/2308.16369

Splitwise - https://arxiv.org/abs/2311.18677

DistServe - https://arxiv.org/abs/2401.09670

Fairness - https://arxiv.org/abs/2401.00588

APIServe - https://arxiv.org/html/2402.01869v1

SGLang - https://arxiv.org/html/2312.07104v1

LayerSkip - https://arxiv.org/abs/2404.16710

Parrot - https://arxiv.org/abs/2405.19888 (Optional)

# Multi-Token Prediction 

Lookahead Decoding - https://arxiv.org/abs/2402.02057

Medusa - https://arxiv.org/abs/2401.10774

Speculative Decoding - https://arxiv.org/abs/2211.17192


# Multiple LLM and multiple LoRa serving

MuxServe - https://arxiv.org/abs/2404.02015

s-LoRa - https://arxiv.org/abs/2311.03285

# Hallucinations

DoLa - https://arxiv.org/abs/2309.03883

# New Architectures

Mamba - https://arxiv.org/abs/2312.00752
Jamba - https://arxiv.org/abs/2403.19887

# MoE

Gshard - https://usenix.org/system/files/osdi22-yu.pdf

SwapMoE - https://arxiv.org/abs/2308.15030

Towards MoE Deployment - https://arxiv.org/abs/2303.06182

MegaBlocks - https://arxiv.org/abs/2211.15841

Tutel - https://arxiv.org/abs/2206.03382

DeepSpeed-MoE: https://arxiv.org/abs/2201.05596

# Quantization and Compression

GPTQ - https://arxiv.org/abs/2210.17323

SmoothQuant - https://arxiv.org/abs/2211.10438

DynaQuant - https://arxiv.org/abs/2306.11800












